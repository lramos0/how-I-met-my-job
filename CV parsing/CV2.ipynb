{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a183e570-071a-4219-980b-20985a2f7a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON saved to parsed_cv.json\n",
      "CSV saved to parsed_cv.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "from PyPDF2 import PdfReader\n",
    "import docx2txt\n",
    "\n",
    "# -------------------------------\n",
    "# Extraction functions\n",
    "# -------------------------------\n",
    "def extract_email(text):\n",
    "    return re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n",
    "\n",
    "def extract_phone(text):\n",
    "    return re.findall(r'\\+?\\d[\\d -]{8,}\\d', text)\n",
    "\n",
    "def extract_projects(text):\n",
    "    lines = text.splitlines()\n",
    "    projects = [line.strip() for line in lines if re.search(r'\\b(project|worked on|involved in|contributed to)\\b', line, re.IGNORECASE)]\n",
    "    return projects\n",
    "\n",
    "def extract_skill_experience(text, skill_dict):\n",
    "    skill_exp = {}\n",
    "    exp_pattern = r'(\\d+\\+?\\-?\\d*\\s*(?:years|yrs))'\n",
    "    for skill, synonyms in skill_dict.items():\n",
    "        for syn in synonyms:\n",
    "            pattern = rf'({syn}).{{0,50}}{exp_pattern}|{exp_pattern}.{{0,50}}({syn})'\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            if matches:\n",
    "                for m in matches:\n",
    "                    exp = next((s for s in m if s.lower() not in [syn.lower(), \"\"]), None)\n",
    "                    if exp:\n",
    "                        skill_exp[skill] = exp.strip()\n",
    "                        break\n",
    "            else:\n",
    "                if re.search(rf'\\b{re.escape(syn)}\\b', text, re.IGNORECASE):\n",
    "                    skill_exp[skill] = \"Not specified\"\n",
    "    return skill_exp\n",
    "\n",
    "def extract_total_experience(text):\n",
    "    matches = re.findall(r'(\\d+\\+?\\-?\\d*)\\s*(?:years|yrs)\\s*(?:of)?\\s*(?:experience)?', text, re.IGNORECASE)\n",
    "    years = []\n",
    "    for m in matches:\n",
    "        try:\n",
    "            years.append(int(re.findall(r'\\d+', m)[0]))\n",
    "        except:\n",
    "            continue\n",
    "    return max(years) if years else \"Not specified\"\n",
    "\n",
    "# -------------------------------\n",
    "# File text extraction\n",
    "# -------------------------------\n",
    "def extract_text_from_pdf(file_path):\n",
    "    text = \"\"\n",
    "    pdf = PdfReader(file_path)\n",
    "    for page in pdf.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def extract_text_from_docx(file_path):\n",
    "    return docx2txt.process(file_path)\n",
    "\n",
    "# -------------------------------\n",
    "# Skill dictionary\n",
    "# -------------------------------\n",
    "skill_dict = {\n",
    "    \"python\": [\"python\", \"python3\", \"cpython\", \"pypy\"],\n",
    "    \"java\": [\"java\", \"openjdk\", \"jdk\", \"jvm\"],\n",
    "    \"javascript\": [\"javascript\", \"js\", \"nodejs\", \"ecmascript\"],\n",
    "    \"typescript\": [\"typescript\", \"ts\"],\n",
    "    \"go\": [\"go\", \"golang\"],\n",
    "    \"c\": [\"c\"],\n",
    "    \"c++\": [\"c++\", \"cpp\"],\n",
    "    \"c#\": [\"c#\", \"csharp\"],\n",
    "    \"ruby\": [\"ruby\", \"ruby on rails\", \"rails\"],\n",
    "    \"php\": [\"php\", \"laravel\", \"symfony\"],\n",
    "    \"rust\": [\"rust\"],\n",
    "    \"kotlin\": [\"kotlin\"],\n",
    "    \"scala\": [\"scala\"],\n",
    "    \"r\": [\"r\", \"r language\"],\n",
    "    \"swift\": [\"swift\"],\n",
    "    \"shell\": [\"shell\", \"bash\", \"zsh\", \"sh\"],\n",
    "    \"perl\": [\"perl\"],\n",
    "    \"sql\": [\"sql\", \"mysql\", \"postgresql\", \"oracle\", \"sqlite\", \"mssql\"],\n",
    "    \"nosql\": [\"nosql\", \"mongodb\", \"cassandra\", \"redis\", \"dynamodb\", \"couchdb\"],\n",
    "    \"big data\": [\"big data\", \"hadoop\", \"spark\", \"mapreduce\", \"hive\", \"pig\"],\n",
    "    \"data engineering\": [\"data engineering\", \"etl\", \"data pipeline\", \"airflow\"],\n",
    "    \"data science\": [\"data science\", \"machine learning\", \"ml\", \"statistics\"],\n",
    "    \"deep learning\": [\"deep learning\", \"neural networks\", \"tensorflow\", \"pytorch\", \"keras\"],\n",
    "    \"mlops\": [\"mlops\", \"model deployment\", \"model serving\", \"sagemaker\", \"mlflow\"],\n",
    "    \"nlp\": [\"nlp\", \"natural language processing\", \"transformers\", \"spacy\", \"nltk\"],\n",
    "    \"computer vision\": [\"computer vision\", \"cv\", \"opencv\"],\n",
    "    \"analytics\": [\"analytics\", \"business intelligence\", \"bi\", \"tableau\", \"power bi\"],\n",
    "    \"rest\": [\"rest\", \"restful api\", \"api\", \"web api\"],\n",
    "    \"graphql\": [\"graphql\"],\n",
    "    \"web frameworks\": [\"django\", \"flask\", \"express\", \"spring\", \"rails\", \"fastapi\"],\n",
    "    \"frontend frameworks\": [\"react\", \"angular\", \"vue\", \"svelte\", \"ember\"],\n",
    "    \"html\": [\"html\", \"html5\"],\n",
    "    \"css\": [\"css\", \"css3\", \"scss\", \"sass\", \"less\"],\n",
    "    \"webpack\": [\"webpack\", \"rollup\", \"parcel\"],\n",
    "    \"microservices\": [\"microservices\", \"service oriented architecture\", \"soa\"],\n",
    "    \"devops\": [\"devops\", \"ci/cd\", \"continuous integration\", \"continuous delivery\", \"continuous deployment\"],\n",
    "    \"docker\": [\"docker\", \"containers\"],\n",
    "    \"kubernetes\": [\"kubernetes\", \"k8s\", \"kube\"],\n",
    "    \"terraform\": [\"terraform\"],\n",
    "    \"ansible\": [\"ansible\"],\n",
    "    \"chef\": [\"chef\"],\n",
    "    \"puppet\": [\"puppet\"],\n",
    "    \"helm\": [\"helm\"],\n",
    "    \"istio\": [\"istio\", \"service mesh\"],\n",
    "    \"prometheus\": [\"prometheus\", \"grafana\", \"monitoring\"],\n",
    "    \"logging\": [\"elk\", \"elasticsearch\", \"logstash\", \"kibana\", \"splunk\"],\n",
    "    \"cloud aws\": [\"aws\", \"amazon web services\", \"ec2\", \"s3\", \"lambda\", \"cloudformation\", \"iam\", \"dynamodb\"],\n",
    "    \"cloud azure\": [\"azure\", \"microsoft azure\", \"azure functions\", \"azure devops\", \"arm templates\"],\n",
    "    \"cloud gcp\": [\"gcp\", \"google cloud\", \"google cloud platform\", \"gce\", \"bigquery\", \"cloud functions\"],\n",
    "    \"openstack\": [\"openstack\"],\n",
    "    \"serverless\": [\"serverless\", \"faas\"],\n",
    "    \"edge computing\": [\"edge computing\"],\n",
    "    \"networking\": [\"networking\", \"dns\", \"http\", \"tcp/ip\"],\n",
    "    \"security\": [\"security\", \"kubernetes security\", \"oauth2\", \"jwt\", \"tls\", \"ssl\", \"vault\"],\n",
    "    \"git\": [\"git\", \"gitlab\", \"github\", \"bitbucket\"],\n",
    "    \"ci tools\": [\"jenkins\", \"circleci\", \"travis ci\", \"github actions\", \"gitlab ci\", \"azure pipelines\"],\n",
    "    \"jira\": [\"jira\", \"confluence\"],\n",
    "    \"slack\": [\"slack\"],\n",
    "    \"docker-compose\": [\"docker-compose\", \"compose\"],\n",
    "    \"testing\": [\"testing\", \"unit test\", \"integration test\", \"pytest\", \"junit\", \"mocha\", \"jest\"],\n",
    "    \"performance\": [\"performance\", \"profiling\", \"benchmark\"],\n",
    "    \"cache\": [\"cache\", \"redis\", \"memcached\"],\n",
    "    \"microservices architecture\": [\"microservices architecture\", \"soa\", \"service mesh\"],\n",
    "    \"design patterns\": [\"design patterns\", \"solid\", \"ddd\", \"clean architecture\"],\n",
    "    \"architecture\": [\"architecture\", \"system design\", \"scalability\", \"high availability\"],\n",
    "    \"agile\": [\"agile\", \"scrum\", \"kanban\"],\n",
    "    \"devsecops\": [\"devsecops\", \"security as code\", \"shift left\"],\n",
    "    \"observability\": [\"observability\", \"opentelemetry\", \"logging\", \"tracing\", \"metrics\"]\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# Main parser\n",
    "# -------------------------------\n",
    "def parse_cv(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File does not exist: {file_path}\")\n",
    "    \n",
    "    if file_path.lower().endswith(\".pdf\"):\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "    elif file_path.lower().endswith(\".docx\"):\n",
    "        text = extract_text_from_docx(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Only PDF or DOCX files are supported\")\n",
    "    \n",
    "    #name_line = text.strip().splitlines()[0]\n",
    "   # name = name_line.strip() if len(name_line) < 100 else \"\"\n",
    "\n",
    "    emails = extract_email(text)\n",
    "    phones = extract_phone(text)\n",
    "    projects = extract_projects(text)\n",
    "    skills_experience = extract_skill_experience(text, skill_dict)\n",
    "    total_experience = extract_total_experience(text)\n",
    "\n",
    "    cv_json = {\n",
    "       # \"Name\": name,\n",
    "        \"Email\": emails,\n",
    "        \"Phone\": phones,\n",
    "        \"Total_Experience\": total_experience,\n",
    "        \"Skills_Experience\": skills_experience,\n",
    "        \"Project_Highlights\": projects\n",
    "    }\n",
    "\n",
    "    return cv_json\n",
    "\n",
    "# -------------------------------\n",
    "# Save to JSON and CSV\n",
    "# -------------------------------\n",
    "def save_cv(cv_data, json_file, csv_file):\n",
    "    # Save JSON\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(cv_data, f, indent=4)\n",
    "    \n",
    "    # Save CSV\n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([ \"Email\", \"Phone\", \"Total_Experience\", \"Skill\", \"Skill_Experience\", \"Project_Highlights\"])\n",
    "        for skill, exp in cv_data[\"Skills_Experience\"].items():\n",
    "            writer.writerow([\n",
    "                cv_data[\"Email\"],\n",
    "                \", \".join(cv_data[\"Phone\"]),\n",
    "                cv_data[\"Total_Experience\"],\n",
    "                skill,\n",
    "                exp,\n",
    "                \" | \".join(cv_data[\"Project_Highlights\"])\n",
    "            ])\n",
    "\n",
    "# -------------------------------\n",
    "# Example usage\n",
    "# -------------------------------\n",
    "file_path = r\"C:\\Users\\takbh\\BDA696\\venv2\\how-I-met-my-job\\UmaTakbhate_Resume.pdf\"  # or .docx\n",
    "parsed_cv = parse_cv(file_path)\n",
    "\n",
    "# Output files\n",
    "json_file = \"parsed_cv.json\"\n",
    "csv_file = \"parsed_cv.csv\"\n",
    "\n",
    "save_cv(parsed_cv, json_file, csv_file)\n",
    "\n",
    "print(f\"JSON saved to {json_file}\")\n",
    "print(f\"CSV saved to {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d8421-30f5-4aee-be6c-e63bd1b7b982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
